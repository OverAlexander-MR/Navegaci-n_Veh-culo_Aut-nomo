@book{Accidentes,
  title        = {Informe sobre la situación mundial de la seguridad vial 2023},
  author       = {{Organización Mundial de la Salud}},
  year         = 2023,
  publisher    = {Organización Mundial de la Salud},
  address      = {Ginebra, Suiza},
  url          = {https://www.who.int/publications/i/item/9789241565684}
}

@INPROCEEDINGS{Smart_Agent,
  author={Lamouik, Imad and Yahyaouy, Ali and Sabri, My Abdelouahed},
  booktitle={2017 International Conference on Advanced Technologies for Signal and Image Processing (ATSIP)}, 
  title={Smart multi-agent traffic coordinator for autonomous vehicles at intersections}, 
  year={2017},
  pages={1-6},
  doi={10.1109/ATSIP.2017.8075564}
}

@article{Reinfor_Control,
  title = {A comprehensive review on safe reinforcement learning for autonomous vehicle control in dynamic environments},
  journal = {e-Prime - Advances in Electrical Engineering, Electronics and Energy},
  volume = {10},
  pages = {100810},
  year = {2024},
  issn = {2772-6711},
  doi = {https://doi.org/10.1016/j.prime.2024.100810},
  url = {https://www.sciencedirect.com/science/article/pii/S2772671124003905},
  author = {Rohan Inamdar and S. Kavin Sundarr and Deepen Khandelwal and Varun Dev Sahu and Nitish Katal}
}

@article{traffic_lights,
  title = {Reinforcement learning based adaptive control method for traffic lights in intelligent transportation},
  journal = {Alexandria Engineering Journal},
  volume = {106},
  pages = {381-391},
  year = {2024},
  issn = {1110-0168},
  doi = {https://doi.org/10.1016/j.aej.2024.07.046},
  url = {https://www.sciencedirect.com/science/article/pii/S111001682400766X},
  author = {Zhongyi Huang}
}

@INPROCEEDINGS{Smart_Car,
  author={Araujo, Paulo Ricardo Marques and Mounier, Eslam and Dawson, Emma and Noureldin, Aboelmagd},
  booktitle={2024 IEEE International Conference on Smart Mobility (SM)}, 
  title={Smart Mobility: Leveraging Perception Sensors for Map-Based Navigation in Autonomous Vehicles}, 
  year={2024},
  pages={281-286},
  doi={10.1109/SM63044.2024.10733404}
}

@ARTICLE{Smart_Car_ADP,
  author={Hu, Chuan and Wang, Ziao and Bu, Xiangwei and Zhao, Jun and Na, Jing and Gao, Hongbo},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Optimal Tracking Control for Autonomous Vehicle With Prescribed Performance via Adaptive Dynamic Programming}, 
  year={2024},
  volume={25},
  number={9},
  pages={12437-12449},
  doi={10.1109/TITS.2024.3384113}
}

@article{Smart_Car_DQN,
  title = {Highly accurate map construction and deep Q-network for autonomous driving and smart transportation},
  journal = {Computers and Electrical Engineering},
  volume = {110},
  pages = {108899},
  year = {2023},
  issn = {0045-7906},
  doi = {https://doi.org/10.1016/j.compeleceng.2023.108899},
  url = {https://www.sciencedirect.com/science/article/pii/S0045790623003233},
  author = {Xiaowei Sun and Huili Dou and Zhiguo Zhou}
}

@article{Smart_Car_PPO,
  author = {Leandro Parada, Eduardo Candela, Luis Marques and Panagiotis Angeloudis},
  title = {Safe and efficient manoeuvring for emergency vehicles in autonomous traffic using multi-agent proximal policy optimisation},
  journal = {Transportmetrica A: Transport Science},
  year = {2023},
  volume = {0},
  number = {0},
  pages = {1--29},
  publisher = {Taylor \& Francis},
  doi = {10.1080/23249935.2023.2246586}
}

@article{DQN_Inf,
  title = {A hyper-heuristic with deep Q-network for the multi-objective unmanned surface vehicles scheduling problem},
  journal = {Neurocomputing},
  volume = {596},
  pages = {127943},
  year = {2024},
  issn = {0925-2312},
  doi = {https://doi.org/10.1016/j.neucom.2024.127943},
  url = {https://www.sciencedirect.com/science/article/pii/S0925231224007148},
  author = {Ningjun Xu and Zhangsong Shi and Shihong Yin and Zhengrong Xiang},
  keywords = {Multi-objective optimization, Unmanned surface vehicle, Coverage path planning, Hyper-heuristic algorithm, Deep reinforcement learning}
}

@article{ADP_Inf,
  title = {Trajectory tracking control for underactuated autonomous vehicles via adaptive dynamic programming},
  journal = {Journal of the Franklin Institute},
  volume = {361},
  number = {1},
  pages = {474-488},
  year = {2024},
  issn = {0016-0032},
  doi = {https://doi.org/10.1016/j.jfranklin.2023.12.003},
  url = {https://www.sciencedirect.com/science/article/pii/S0016003223007676},
  author = {Xiumei Han and Xudong Zhao and Xiaolu Xu and Congli Mei and Wei Xing and Xinwei Wang},
  keywords = {Trajectory tracking control, Underactuated autonomous vehicles, Indirect robust control, Optimal control, Policy iteration, Adaptive dynamic programming}
}

@article{PPO_Inf,
  title = {Proximal policy optimization with reciprocal velocity obstacle based collision avoidance path planning for multi-unmanned surface vehicles},
  journal = {Ocean Engineering},
  volume = {273},
  pages = {114005},
  year = {2023},
  issn = {0029-8018},
  doi = {https://doi.org/10.1016/j.oceaneng.2023.114005},
  url = {https://www.sciencedirect.com/science/article/pii/S002980182300389X},
  author = {Delai Xue and Defeng Wu and Andre S. Yamashita and Zhixiong Li},
  keywords = {Multi-USVs, Proximal policy optimization, Reciprocal velocity obstacle, COLREGS collision avoidance, Path planning}
}

@article{arshad2020clothoid,
  author = {Saba Arshad and Muhammad Sualeh and Dohyeong Kim and Dinh Van Nam and Gon-Woo Kim},
  title = {Clothoid: An Integrated Hierarchical Framework for Autonomous Driving in a Dynamic Urban Environment},
  journal = {Sensors},
  volume = {20},
  number = {18},
  pages = {5053},
  year = {2020},
  doi = {10.3390/s20185053},
  url = {https://research.ebsco.com/linkprocessor/plink?id=0d501679-ad5e-3650-956f-f38dba4076eb},
  publisher = {MDPI},
  language = {English},
  issn = {1424-8220}
}

@article{Double-DQN,
  title = {Double-DQN based path smoothing and tracking control method for robotic vehicle navigation},
  journal = {Computers and Electronics in Agriculture},
  volume = {166},
  pages = {104985},
  year = {2019},
  issn = {0168-1699},
  doi = {https://doi.org/10.1016/j.compag.2019.104985},
  url = {https://www.sciencedirect.com/science/article/pii/S0168169919302066},
  author = {Wenyu Zhang and Jingyao Gai and Zhigang Zhang and Lie Tang and Qingxi Liao and Youchun Ding}
}

@ARTICLE{ADP_A,
  author={Lin, Ziyu and Ma, Jun and Duan, Jingliang and Li, Shengbo Eben and Ma, Haitong and Cheng, Bo and Lee, Tong Heng},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Policy Iteration Based Approximate Dynamic Programming Toward Autonomous Driving in Constrained Dynamic Environment}, 
  year={2023},
  volume={24},
  number={5},
  pages={5003-5013},
  doi={10.1109/TITS.2023.3237568}
}

@ARTICLE{Control_Optimal_Traking,
  author={Hu, Chuan and Wang, Ziao and Bu, Xiangwei and Zhao, Jun and Na, Jing and Gao, Hongbo},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Optimal Tracking Control for Autonomous Vehicle With Prescribed Performance via Adaptive Dynamic Programming}, 
  year={2024},
  volume={25},
  number={9},
  pages={12437-12449},
  doi={10.1109/TITS.2024.3384113}
}

@article{A_dqn,
title = {A* guiding DQN algorithm for automated guided vehicle pathfinding problem of robotic mobile fulfillment systems},
journal = {Computers \& Industrial Engineering},
volume = {178},
pages = {109112},
year = {2023},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2023.109112},
url = {https://www.sciencedirect.com/science/article/pii/S0360835223001365},
author = {Lei Luo and Ning Zhao and Yi Zhu and Yangjun Sun},
keywords = {RMFS, Pathfinding, Reinforcement learning, DQN algorithm, A* algorithm}}

@article{movile,
title = {Obstacle avoidance method based on reinforcement learning dual-layer decision model for AGV with visual perception},
journal = {Control Engineering Practice},
volume = {153},
pages = {106121},
year = {2024},
issn = {0967-0661},
doi = {https://doi.org/10.1016/j.conengprac.2024.106121},
url = {https://www.sciencedirect.com/science/article/pii/S0967066124002806},
author = {Jun Nie and Guihua Zhang and Xiao Lu and Haixia Wang and Chunyang Sheng and Lijie Sun}
}

@article{dqn_va,
title = {Modeling and simulation of a double DQN algorithm for dynamic obstacle avoidance in autonomous vehicle navigation},
journal = {e-Prime - Advances in Electrical Engineering, Electronics and Energy},
volume = {8},
pages = {100581},
year = {2024},
issn = {2772-6711},
doi = {https://doi.org/10.1016/j.prime.2024.100581},
url = {https://www.sciencedirect.com/science/article/pii/S277267112400161X},
author = {Kappagantula Sivayazi and Giriraj Mannayee}}

@article{NEAT,
title = {Agent-based evacuation modeling with multiple exits using NeuroEvolution of Augmenting Topologies},
journal = {Advanced Engineering Informatics},
volume = {35},
pages = {30-55},
year = {2018},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2017.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1474034616304281},
author = {Mehmet Erkan Yuksel}}

@incollection{NEAT_2,
title = {Decision-making of online rescheduling procedures using neuroevolution of augmenting topologies},
editor = {Anton A. Kiss and Edwin Zondervan and Richard Lakerveld and Leyla Özkan},
series = {Computer Aided Chemical Engineering},
publisher = {Elsevier},
volume = {46},
pages = {1177-1182},
year = {2019},
booktitle = {29th European Symposium on Computer Aided Process Engineering},
issn = {1570-7946},
doi = {https://doi.org/10.1016/B978-0-12-818634-3.50197-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780128186343501971},
author = {Teemu J. Ikonen and Iiro Harjunkoski}}

@article{RAS,
title = {A deep residual reinforcement learning algorithm based on Soft Actor-Critic for autonomous navigation},
journal = {Expert Systems with Applications},
volume = {259},
pages = {125238},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125238},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424021055},
author = {Shuhuan Wen and Yili Shu and Ahmad Rad and Zeteng Wen and Zhengzheng Guo and Simeng Gong}
}

@thesis{NAT_R,
  author = {Felix Coto Guardo},
  title = {Evolución de redes neuronales mediante topologías aumentadas},
  school = {Universidad Autónoma de Madrid},
  year = {2019},
  type = {Trabajo Fin de Grado},
  address = {Madrid, España},
  month = {6}
}

@article{SAC,
title = {Optimal navigation for AGVs: A soft actor–critic-based reinforcement learning approach with composite auxiliary rewards},
journal = {Engineering Applications of Artificial Intelligence},
volume = {124},
pages = {106613},
year = {2023},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2023.106613},
url = {https://www.sciencedirect.com/science/article/pii/S0952197623007972},
author = {Haisen Guo and Zhigang Ren and Jialun Lai and Zongze Wu and Shengli Xie}
}

@article{red_neuronal,
  title={A Beginner's Guide to Neural Networks in Python},
  author={Portilla, Jose},
  journal={Springboard Blog},
  year={2017},
  url={https://www.springboard.com/blog/data-science/beginners-guide-neural-network-in-python-scikit-learn-0-18/}
}
@article{sensores,
  title        = {NEAT Algorithm in Autonomous Vehicles},
  author       = {Robin Lauckner and Hoshang Kolivand},
  year         = {2023},
  institution  = {Liverpool John Moores University},
  note         = {Preprint, not peer-reviewed},
  url          = {https://ssrn.com/abstract=4644203},
  journal      = {}   
}
@misc{neat_python,
  author = {CodeReclaimers, LLC},
  title = {Overview of the basic XOR example (evolve-feedforward.py)},
  year = {2019},
  url= {https://neat-python.readthedocs.io/en/latest/xor_example.html#fitness-function},
  note = {Accessed: 2024-11-18}
}
@misc{dqn_math,
  author = {Jay Bailey},
  title = {Deep Q-Networks Explained},
  year = {2022},
  howpublished = {\url{https://www.lesswrong.com/posts/kyvCNgx9oAwJCuevo/deep-q-networks-explained}},
  note = {Accessed: 2024-11-18}
}
@article{atari,
  author       = {Volodymyr Mnih and
                  Koray Kavukcuoglu and
                  David Silver and
                  Alex Graves and
                  Ioannis Antonoglou and
                  Daan Wierstra and
                  Martin A. Riedmiller},
  title        = {Playing Atari with Deep Reinforcement Learning},
  journal      = {CoRR},
  volume       = {abs/1312.5602},
  year         = {2013},
  url          = {http://arxiv.org/abs/1312.5602},
  eprinttype    = {arXiv},
  eprint       = {1312.5602},
  timestamp    = {Mon, 13 Aug 2018 16:47:42 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/MnihKSGAWR13.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}